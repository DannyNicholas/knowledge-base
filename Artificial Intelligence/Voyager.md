
[2305.16291.pdf (arxiv.org)](https://arxiv.org/pdf/2305.16291.pdf)

1) **Automatic curriculum** to maximise exploration
2) Ever-growing library **skill library** of executable code for storing and retrieving complex behaviours
3) **Iterative prompting mechanism** that incorporates environmental feedback, execution errors and self-verification for improvement

![[voyager1.png]]

## Automatic Curriculum

### Adding a New Skill 

Each time GPT-4 generates and verifies a new skill, we add it to the skill library, represented by a vector database. The key is the embedding vector of the program description (generated by GPT-3.5), while the value is the program itself.
![[voyager2.png]]

### Skill Retrieval

When faced with a new task proposed by the automatic curriculum, we first leverage GPT-3.5 to generate a general suggestion for solving the task, which is combined with environment feedback as the query context. Subsequently, we perform querying to identify the top-5 relevant skills

![[voyager3.png]]


The input prompt to GPT-4 consists of several components:

1) Directives encouraging diverse behaviors and imposing constraints, such as “`My ultimate goal is to discover as many diverse things as possible ... The next task should not be too hard since I may not have the necessary resources or have learned enough skills to complete it yet`.”
2) The agent’s current state, including inventory, equipment, nearby blocks and entities, biome, time, health and hunger bars, and position
3) Previously completed and failed tasks, reflecting the agent’s current exploration progress and capabilities frontier
4) Additional context: We also leverage GPT-3.5 to self-ask questions based on the agent’s current state and exploration progress and self-answer questions. We opt to use GPT-3.5 instead of GPT-4 for standard NLP tasks due to budgetary considerations

## Skills Library

We represent each skill with executable code that scaffolds temporally extended actions for completing a specific task proposed by the automatic curriculum.

The input prompt to GPT-4 consists of the following components:

1) Guidelines for code generation, such as “`Your function will be reused for building more complex functions. Therefore, you should make it generic and reusable.`”
2) Control primitive APIs, and relevant skills retrieved from the skill library, which are crucial for in-context learning to work well.
3) The generated code from the last round, environment feedback, execution errors, and critique, based on which GPT-4 can self-improve
4) The agent’s current state, including inventory, equipment, nearby blocks and entities, biome, time, health and hunger bars, and position.

### Environment feedback

GPT-4 realizes it needs 2 more planks before crafting sticks:

![[voyager4.png]]


### Execution Error

GPT-4 realises it should craft a wooden axe instead of an acacia axe since there is no acacia axe in Minecraft.
![[voyager5.png]]

## Iterative Prompting Mechanism

We introduce an iterative prompting mechanism for self-improvement through three types of feedback:

1) **Environment feedback**, which illustrates the intermediate progress of program execution (Fig. 5, left). For example, “`I cannot make an iron chestplate because I need: 7 more iron ingots`” highlights the cause of failure in crafting an iron chestplate. We use bot.chat() inside control primitive APIs to generate environment feedback and prompt GPT-4 to use this function as well during code generation.
2) **Execution errors** from the program interpreter that reveal any invalid operations or syntax errors in programs, which are valuable for bug fixing.
3) **Self-verification for checking task success**. Instead of manually coding success checkers for each new task proposed by the automatic curriculum, we instantiate another GPT-4 agent for self-verification. By providing VOYAGER’s current state and the task to GPT-4, we ask it to act as a critic and inform us whether the program achieves the task. In addition, if the task fails, it provides a critique by suggesting how to complete the task. Hence, our self-verification is more comprehensive than self-reflection by both checking success and reflecting on mistakes

During each round of code generation, we execute the generated program to obtain environment
feedback and execution errors from the code interpreter, which are incorporated into GPT-4’s prompt for the next round of code refinement. This iterative process repeats until self-verification validates the task’s completion, at which point we add this new skill to the skill library and ask the automatic curriculum for a new objective. If the agent gets stuck after 4 rounds of code generation, then we query the curriculum for another task. This iterative prompting approach significantly improves
program synthesis for embodied control, enabling VOYAGER to continuously acquire diverse skills
without human intervention.

### Self-Verification Process

![[voyager6.png]]